{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9  ...       V21       V22       V23       V24       V25  \\\n0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n\n        V26       V27       V28  Amount  Class  \n0 -0.189115  0.133558 -0.021053  149.62      0  \n1  0.125895 -0.008983  0.014724    2.69      0  \n2 -0.139097 -0.055353 -0.059752  378.66      0  \n3 -0.221929  0.062723  0.061458  123.50      0  \n4  0.502292  0.219422  0.215153   69.99      0  \n\n[5 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>...</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>...</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>...</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('datasets/creditcard/creditcard.csv')\n",
    "data.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0, 0.5, 'Frequent')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Class_count = pd.value_counts(data['Class'],sort=True,).sort_index()\n",
    "Class_count.plot(kind='bar')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequent')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([   541,    623,   4920,   6108,   6329,   6331,   6334,   6336,\n         6338,   6427,   6446,   6472,   6529,   6609,   6641,   6717,\n         6719,   6734,   6774,   6820,   6870,   6882,   6899,   6903,\n         6971,   8296,   8312,   8335,   8615,   8617,   8842,   8845,\n         8972,   9035,   9179,   9252,   9487,   9509,  10204,  10484,\n        10497,  10498,  10568,  10630,  10690,  10801,  10891,  10897,\n        11343,  11710,  11841,  11880,  12070,  12108,  12261,  12369,\n        14104,  14170,  14197,  14211,  14338,  15166,  15204,  15225,\n        15451,  15476,  15506,  15539,  15566,  15736,  15751,  15781,\n        15810,  16415,  16780,  16863,  17317,  17366,  17407,  17453,\n        17480,  18466,  18472,  18773,  18809,  20198,  23308,  23422,\n        26802,  27362,  27627,  27738,  27749,  29687,  30100,  30314,\n        30384,  30398,  30442,  30473,  30496,  31002,  33276,  39183,\n        40085,  40525,  41395,  41569,  41943,  42007,  42009,  42473,\n        42528,  42549,  42590,  42609,  42635,  42674,  42696,  42700,\n        42741,  42756,  42769,  42784,  42856,  42887,  42936,  42945,\n        42958,  43061,  43160,  43204,  43428,  43624,  43681,  43773,\n        44001,  44091,  44223,  44270,  44556,  45203,  45732,  46909,\n        46918,  46998,  47802,  48094,  50211,  50537,  52466,  52521,\n        52584,  53591,  53794,  55401,  56703,  57248,  57470,  57615,\n        58422,  58761,  59539,  61787,  63421,  63634,  64329,  64411,\n        64460,  68067,  68320,  68522,  68633,  69498,  69980,  70141,\n        70589,  72757,  73784,  73857,  74496,  74507,  74794,  75511,\n        76555,  76609,  76929,  77099,  77348,  77387,  77682,  79525,\n        79536,  79835,  79874,  79883,  80760,  81186,  81609,  82400,\n        83053,  83297,  83417,  84543,  86155,  87354,  88258,  88307,\n        88876,  88897,  89190,  91671,  92777,  93424,  93486,  93788,\n        94218,  95534,  95597,  96341,  96789,  96994,  99506, 100623,\n       101509, 102441, 102442, 102443, 102444, 102445, 102446, 102782,\n       105178, 106679, 106998, 107067, 107637, 108258, 108708, 111690,\n       112840, 114271, 116139, 116404, 118308, 119714, 119781, 120505,\n       120837, 122479, 123141, 123201, 123238, 123270, 123301, 124036,\n       124087, 124115, 124176, 125342, 128479, 131272, 135718, 137705,\n       140786, 141257, 141258, 141259, 141260, 142405, 142557, 143188,\n       143333, 143334, 143335, 143336, 143728, 143731, 144104, 144108,\n       144754, 145800, 146790, 147548, 147605, 149145, 149357, 149522,\n       149577, 149587, 149600, 149869, 149874, 150601, 150644, 150647,\n       150654, 150660, 150661, 150662, 150663, 150665, 150666, 150667,\n       150668, 150669, 150677, 150678, 150679, 150680, 150684, 150687,\n       150692, 150697, 150715, 150925, 151006, 151007, 151008, 151009,\n       151011, 151103, 151196, 151462, 151519, 151730, 151807, 152019,\n       152223, 152295, 153823, 153835, 153885, 154234, 154286, 154371,\n       154454, 154587, 154633, 154668, 154670, 154676, 154684, 154693,\n       154694, 154697, 154718, 154719, 154720, 154960, 156988, 156990,\n       157585, 157868, 157871, 157918, 163149, 163586, 167184, 167305,\n       172787, 176049, 177195, 178208, 181966, 182992, 183106, 184379,\n       189587, 189701, 189878, 190368, 191074, 191267, 191359, 191544,\n       191690, 192382, 192529, 192584, 192687, 195383, 197586, 198868,\n       199896, 201098, 201601, 203324, 203328, 203700, 204064, 204079,\n       204503, 208651, 212516, 212644, 213092, 213116, 214662, 214775,\n       215132, 215953, 215984, 218442, 219025, 219892, 220725, 221018,\n       221041, 222133, 222419, 223366, 223572, 223578, 223618, 226814,\n       226877, 229712, 229730, 230076, 230476, 231978, 233258, 234574,\n       234632, 234633, 234705, 235616, 235634, 235644, 237107, 237426,\n       238222, 238366, 238466, 239499, 239501, 240222, 241254, 241445,\n       243393, 243547, 243699, 243749, 243848, 244004, 244333, 245347,\n       245556, 247673, 247995, 248296, 248971, 249167, 249239, 249607,\n       249828, 249963, 250761, 251477, 251866, 251881, 251891, 251904,\n       252124, 252774, 254344, 254395, 255403, 255556, 258403, 261056,\n       261473, 261925, 262560, 262826, 263080, 263274, 263324, 263877,\n       268375, 272521, 274382, 274475, 275992, 276071, 276864, 279863,\n       280143, 280149, 281144, 281674])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#异常数量\n",
    "errorNum = len(data[data.Class == 1])\n",
    "print(errorNum)\n",
    "#异常索引\n",
    "errorArrIndex = np.array(data[data.Class == 1].index)\n",
    "errorArrIndex"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data['newAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1,1))\n",
    "data = data.drop(['Time','Amount'],axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample: 492\n",
      "error: 492\n"
     ]
    }
   ],
   "source": [
    "#下采样——正常数向下匹配异常数\n",
    "#正常数索引\n",
    "normalArrIndexAll = np.array(data[data.Class == 0].index)\n",
    "#根据异常数随机从正常中获取相同数量的索引\n",
    "normalArrIndex = np.random.choice(normalArrIndexAll, errorNum, replace=False)\n",
    "normalArrIndex = np.array(normalArrIndex)\n",
    "\n",
    "#整合索引\n",
    "underIndex = np.concatenate([normalArrIndex,errorArrIndex])\n",
    "#获取所有采取点\n",
    "underSample = data.iloc[underIndex,:]\n",
    "#print(underSample)\n",
    "#两类所占比例\n",
    "print('sample:',len(underSample[underSample.Class==0]))\n",
    "print('error:',len(underSample[underSample.Class==1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始训练集包含样本数 199364\n",
      "原始测试集包含样本数 85443\n",
      "原始训练集包含样本数 688\n",
      "原始测试集包含样本数 296\n"
     ]
    }
   ],
   "source": [
    "#交叉验证——数据集划分成多个训练集与测试集一起，每次取一个做验证集，之后多个验证集取平均得到结果\n",
    "#获取特征——删除Class列\n",
    "X = data.iloc[:,lambda df : data.columns != 'Class']\n",
    "X_sample = underSample.iloc[:,lambda df : underSample.columns != 'Class']\n",
    "\n",
    "#标签\n",
    "y = data.iloc[:,lambda df : data.columns == 'Class']\n",
    "y_sample = underSample.iloc[:,lambda df : underSample.columns == 'Class']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.3, random_state=0)\n",
    "print('原始训练集包含样本数',len(X_train))\n",
    "print('原始测试集包含样本数',len(X_test))\n",
    "\n",
    "X_sample_train,X_sample_test,y_sample_train,y_sample_test = train_test_split(X_sample,y_sample,test_size=.3, random_state=0)\n",
    "print('原始训练集包含样本数',len(X_sample_train))\n",
    "print('原始测试集包含样本数',len(X_sample_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "正则化惩罚力度： 0.01\n",
      "----------------\n",
      "\n",
      "Iteration  1 : 召回率 =  0.9230769230769231\n",
      "Iteration  2 : 召回率 =  0.8615384615384616\n",
      "Iteration  3 : 召回率 =  0.8227848101265823\n",
      "Iteration  4 : 召回率 =  0.9206349206349206\n",
      "Iteration  5 : 召回率 =  0.8873239436619719\n",
      "\n",
      "平均召回率  0.883071811807772\n",
      "\n",
      "----------------\n",
      "正则化惩罚力度： 0.1\n",
      "----------------\n",
      "\n",
      "Iteration  1 : 召回率 =  0.9230769230769231\n",
      "Iteration  2 : 召回率 =  0.8923076923076924\n",
      "Iteration  3 : 召回率 =  0.8481012658227848\n",
      "Iteration  4 : 召回率 =  0.9365079365079365\n",
      "Iteration  5 : 召回率 =  0.9295774647887324\n",
      "\n",
      "平均召回率  0.9059142565008138\n",
      "\n",
      "----------------\n",
      "正则化惩罚力度： 1\n",
      "----------------\n",
      "\n",
      "Iteration  1 : 召回率 =  0.9230769230769231\n",
      "Iteration  2 : 召回率 =  0.8923076923076924\n",
      "Iteration  3 : 召回率 =  0.8227848101265823\n",
      "Iteration  4 : 召回率 =  0.9365079365079365\n",
      "Iteration  5 : 召回率 =  0.9295774647887324\n",
      "\n",
      "平均召回率  0.9008509653615733\n",
      "\n",
      "----------------\n",
      "正则化惩罚力度： 10\n",
      "----------------\n",
      "\n",
      "Iteration  1 : 召回率 =  0.9384615384615385\n",
      "Iteration  2 : 召回率 =  0.8769230769230769\n",
      "Iteration  3 : 召回率 =  0.8354430379746836\n",
      "Iteration  4 : 召回率 =  0.9365079365079365\n",
      "Iteration  5 : 召回率 =  0.9295774647887324\n",
      "\n",
      "平均召回率  0.9033826109311935\n",
      "\n",
      "----------------\n",
      "正则化惩罚力度： 100\n",
      "----------------\n",
      "\n",
      "Iteration  1 : 召回率 =  0.9384615384615385\n",
      "Iteration  2 : 召回率 =  0.8769230769230769\n",
      "Iteration  3 : 召回率 =  0.8354430379746836\n",
      "Iteration  4 : 召回率 =  0.9365079365079365\n",
      "Iteration  5 : 召回率 =  0.9295774647887324\n",
      "\n",
      "平均召回率  0.9033826109311935\n",
      "\n",
      "------------------------\n",
      "best parameter =  0.1\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "#建模\n",
    "def printing_Kfold_scores(x_train_data,y_train_data):\n",
    "    fold = KFold(5,shuffle=False)\n",
    "    #正则化惩罚力度\n",
    "    c_param_range = [.01, .1, 1, 10, 100]\n",
    "    #展示\n",
    "    res_table = pd.DataFrame(index=range(len(c_param_range),2), columns=['C_parameter','Mean recall score'])\n",
    "    res_table['C_parameter'] = c_param_range\n",
    "    #k_fold返回训练集indices[0]和验证集indices[1]\n",
    "    j = 0\n",
    "    for c_param in c_param_range:\n",
    "        print('----------------')\n",
    "        print('正则化惩罚力度：',c_param)\n",
    "        print('----------------')\n",
    "        print('')\n",
    "        recall_accs = []\n",
    "\n",
    "        for iteration, indices in enumerate(fold.split(y_train_data),start=1):\n",
    "            #算法模型\n",
    "            lr = LogisticRegression(C=c_param,penalty='l2',solver='lbfgs',max_iter=3000)\n",
    "            #训练模型\n",
    "            lr.fit(x_train_data.iloc[indices[0],:],y_train_data.iloc[indices[0],:].values.ravel())\n",
    "            #预测\n",
    "            y_pred_undersample = lr.predict(x_train_data.iloc[indices[1],:].values)\n",
    "            #recall评估\n",
    "            recall_acc = recall_score(y_train_data.iloc[indices[1],:].values, y_pred_undersample)\n",
    "            #放入列表最后求平均值\n",
    "            recall_accs.append(recall_acc)\n",
    "            print('Iteration ',iteration,': 召回率 = ',recall_acc)\n",
    "        res_table.loc[j,'Mean recall score'] = np.mean(recall_accs)\n",
    "        j+=1\n",
    "        print(\"\")\n",
    "        print('平均召回率 ',np.mean(recall_accs))\n",
    "        print('')\n",
    "    best_c = res_table.loc[res_table['Mean recall score'].astype('float32').idxmax()]['C_parameter']\n",
    "\n",
    "    print('------------------------')\n",
    "    print('best parameter = ',best_c)\n",
    "    print('------------------------')\n",
    "    return best_c\n",
    "best_c = printing_Kfold_scores(X_sample_train,y_sample_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
